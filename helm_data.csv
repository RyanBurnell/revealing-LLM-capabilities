Model,MMLU_EM,BoolQ_EM,NarrativeQA_F1,NaturalQuestions_(closed-book)_F1,NaturalQuestions_(open-book)_F1,QuAC_F1,HellaSwag_EM,OpenbookQA_EM,TruthfulQA_EM,MS_MARCO_(regular)_RR@10,MS_MARCO_(TREC)_NDCG@10,CNN/DailyMail_ROUGE-2,XSUM_ROUGE-2,IMDB_EM,CivilComments_EM,RAFT_EM,The_Pile_BPB,TwitterAAE_BPB,ICE_BPB,BLiMP_EM,WikiFact_EM,Synthetic_reasoning_(abstract_symbols)_EM,Synthetic_reasoning_(natural_language)_F1,bAbI_EM,Dyck_EM,GSM8K_EM,MATH_Equivalent,MATH_(chain-of-thoughts)_Equivalent_(chain_of_thought),HumanEval_(Code)_pass@1,LSAT_EM,LegalSupport_EM,Data_imputation_EM,Entity_matching_EM,BBQ_EM
TaskType,Core,Core,Core,Core,Core,Core,Core,Core,Core,Core,Core,Core,Core,Core,Core,Core,Targeted,Targeted,Targeted,Targeted,Targeted,Targeted,Targeted,Targeted,Targeted,Targeted,Targeted,Targeted,Targeted,Targeted,Targeted,Targeted,Targeted,Targeted
HelmTaskClassification,QA,QA,QA,QA,QA,QA,QA,QA,QA,Information Retrieval,Information Retrieval,Summarization,Summarization,SentimentAnalysis,ToxicityClassification,TextClassification,LanguageModelling,LanguageModelling,LanguageModelling,LanguageModelling,Knowledge,Reasoning,Reasoning,Reasoning,Reasoning,Reasoning,Reasoning,Reasoning,Reasoning,Reasoning,Reasoning,Data imputation,Entity matching,Bias
MajorAbility,Mixed,Comprehension,Comprehension,Comprehension,Comprehension,Comprehension,Domain knowledge,Commonsense reasoning,Domain Knowledge,Comprehension,Comprehension,Summarization,Summarization,Comprehension,Comprehension,Comprehension,Language Modelling,Language Modelling,Language Modelling,Language Modelling,Domain Knowledge,Fluid Reasoning,Fluid reasoning,Deductive reasoning,Deductive reasoning,Mathematical reasoning,Mathematical reasoning,Mathematical reasoning,Coding,Fluid reasoning,Inductive reasoning,Unclear,Unclear,Inductive reasoning
taskDescription,"Domain knowledge, given science question and answer multichoice question about it. Need to comprehend answers",Given paragraph and answer multichoice question about it,"Given paragraph and answer question about it - freeform, requires extracting the gist ",Given wikipedia article and answer freeform closed question about it,Given wikipedia article and answer freeform closed question about it,Given article and question answer pairs and then have to answer question about it. Requires extracting the gist / some reasoning,"Commonsense inferences, given a scenario and have to predict what happens next - multichoice options. E.g. A woman is outside with a bucket and a dog. The dog is running around trying to avoid a bath. She (A) rinses the bucket off with soap and blow dries the dog’s head. (B) uses a hose to keep it from getting soapy. (C) gets the dog wet, then it runs away again. (D) gets into the bath tub with the dog. ”, with the desired output: (C)","Commonsense knowledge. Given a question that relies on commonsense knowledge, have to choose the best answer - multichoice. E.g. (Which of these would let the most heat travel through? (A) a new pair of jeans (B) a steel spoon in a cafeteria (C) a cotton candy at a store (D) a calvi klein cotton hat)",Given a general knowledge question that tests for a common misconception / false belief held by humans - multichoice,"Given a bing search query and an answer, decide if the answer is relevant - yes/no","Given a bing search query and an answer, decide if the answer is relevant - yes/no","Given article from CNN/Daily mail, summarise the article","Given BBC article, summarise the article","Given an IMDB review, infer whether the sentiment was positive or negative","Given a comment, need to classify as toxic or not (True/False)","Given a block of text, Classifies the text according to a particular question (e.g. for Neurips risk statement, whether it mentions a harmful application)","Given a big block of text, calculate how well the model predicts that block using Bits per Byte. Text comes from a variety of sources e.g. books, github, ","Given a block of text from twitter, calculate how well the model predicts that block using Bits per Byte","Given a big block of text from the international corpus of english, calculate how well the model predicts that block using Bits per Byte","Given two sentences, one grammatically correct, one incorrect, calculate the difference in log probability between the correct and incorrect sentence - the correct sentence should be more probable","Given the start of a fact (e.g. ""The capital of France is ____"" and has to correctly complete the sentence",Two types of task. Two pattern matching tasks that involve modifying a given input based on a previous set of patterns (similar to Raven's). ,"Given a set of rules and a premise, draw the logical conclusion  - deduction","Given some sentences about people interacting in a house. Then answer some commonsense questions about locations, people, objects, etc. Single word output","Given a set of nested parentheses, predict the last few parentheses to keep everything balanced. E.g. for the input ""(<{ [] } (["" the output would be ""]))""",Natural language school-like mathematical reasoning problems,"Given a mathematics problem in a mix of natural language and Latex, provide the solution. Given 8 context examples. ","Given a mathematics problem in a mix of natural language and Latex, and the solution, provide the chain of thought to get to the answer. Given 8 context examples. ",Coding problems,"Given a natural language reasoning problem (school-like), and asked to answer a question","Given an argument, and the legal conclusions of two court cases. The task is to determine which case most persuasively supports the argument.","Given a set of info about name, phone number, etc of a restaurant, impute the city","Given two entities each with (name, age, etc). Decide if they are the same entity or not (yes/no). Very weird task","Given a scenario, then asked a question about the scenario related to a potential bias of the system (e.g. age bias, gender bias). Sometimes the answer to the question is ambiguous, other times it is unambiguous."
Anthropic-LM-v4-s3,0.481,0.815,0.728,0.288,0.686,0.431,0.807,0.558,0.368,NA,NA,0.154,0.134,0.934,0.61,0.699,0.597,2.109,0.822,0.829,0.336,0.432,0.259,0.461,0.849,0.171,0.198,0.162,NA,0.213,0.624,0.733,0.71,0.551
BLOOM,0.299,0.704,0.662,0.216,0.621,0.361,0.744,0.534,0.205,0.236,0.386,0.08,0.03,0.945,0.62,0.592,0.571,1.986,0.715,0.819,0.221,0.304,0.197,0.447,0.545,0.095,0.043,0.055,NA,0.209,0.543,0.677,0.852,0.375
Cohere-Command-beta,0.452,0.856,0.752,0.372,0.76,0.432,0.811,0.582,0.269,0.472,0.762,0.161,0.152,0.96,0.601,0.667,0.781,2.73,0.943,0.805,0.348,0.243,0.245,0.497,0.421,0.138,0.133,0.075,NA,0.229,0.606,0.752,0.569,0.463
Cohere-Command-beta,0.406,0.798,0.709,0.229,0.717,0.375,0.752,0.55,0.203,0.434,0.709,0.153,0.122,0.961,0.54,0.634,0.875,2.61,1.024,0.79,0.288,0.123,0.254,0.473,0.372,0.036,0.076,0.038,NA,0.178,0.566,0.696,0.532,0.302
Cohere-large-v20220720,0.324,0.725,0.625,0.232,0.573,0.338,0.736,0.542,0.181,0.19,0.33,0.126,0.108,0.933,0.507,0.596,0.811,2.324,0.916,0.833,0.286,0.128,0,0.36,0.531,0.018,0.073,0.035,NA,0.193,0.491,0.71,0.713,0.328
Cohere-medium-v20220720,0.279,0.659,0.559,0.177,0.504,0.279,0.706,0.496,0.19,0.152,0.374,0.077,0.087,0.935,0.504,0.52,0.845,2.341,0.954,0.823,0.254,0.129,0,0.391,0.511,0.015,0.049,0.027,NA,0.212,0.507,0.721,0.482,0.344
Cohere-medium-v20221108,0.254,0.7,0.61,0.199,0.517,0.314,0.726,0.538,0.215,0.175,0.373,0.121,0.099,0.935,0.5,0.591,0.858,2.428,1.009,0.832,0.254,0.096,0,0.471,0.411,0.017,0.052,0.021,NA,0.206,0.489,0.72,0.535,0.359
Cohere-small-v20220720,0.264,0.457,0.294,0.078,0.309,0.219,0.483,0.348,0.217,NA,0.304,0.063,0.033,0.578,0.501,0.492,0.996,2.525,1.112,0.793,0.141,0.121,0,0.306,0.358,0.004,0.016,0.003,NA,0.187,0.524,0.47,0.176,0.363
Cohere-xlarge-v20220609,0.353,0.718,0.65,0.312,0.595,0.361,0.811,0.55,0.198,0.273,0.459,0.144,0.129,0.956,0.532,0.633,0.757,2.305,0.875,0.83,0.336,0.194,0,0.486,0.594,0.07,0.135,0.054,NA,0.2,0.558,0.785,0.823,0.345
Cohere-xlarge-v20221108,0.382,0.762,0.672,0.361,0.628,0.374,0.81,0.588,0.169,0.315,0.55,0.153,0.153,0.956,0.524,0.624,0.741,2.325,0.923,0.832,0.342,0.229,0,0.439,0.587,0.1,0.132,0.063,NA,0.204,0.526,0.803,0.812,0.397
GLM,0.344,0.784,0.706,0.148,0.642,0.272,NA,NA,0.218,NA,NA,0.154,0.132,0.955,0.5,0.598,NA,NA,NA,NA,0.237,0.252,0.254,0.443,0.549,0.061,0,0.059,NA,0.193,0.451,0.66,0.472,0.316
GPT-3-ada,0.243,0.581,0.326,0.082,0.365,0.242,0.435,0.38,0.215,0.102,0.29,0.09,0.022,0.849,0.517,0.423,0.96,2.395,1.136,0.818,0.124,0.1,0.088,0.306,0.406,0.006,0.046,0.006,NA,0.188,0.372,0.582,0.349,0.322
GPT-3-babbage,0.235,0.574,0.491,0.119,0.451,0.273,0.555,0.438,0.188,0.122,0.317,0.079,0.045,0.597,0.519,0.455,0.866,2.291,1.048,0.833,0.184,0.16,0.12,0.348,0.473,0.007,0.048,0.009,NA,0.261,0.492,0.599,0.632,0.319
GPT-3-curie,0.243,0.656,0.604,0.199,0.552,0.321,0.682,0.502,0.232,0.162,0.3,0.113,0.091,0.889,0.539,0.49,0.789,2.21,0.958,0.832,0.236,0.223,0.149,0.415,0.47,0.016,0.05,0.023,NA,0.18,0.49,0.811,0.453,0.362
GPT-3-davinci,0.422,0.722,0.687,0.329,0.625,0.36,0.775,0.586,0.194,0.211,0.378,0.127,0.126,0.933,0.532,0.642,0.713,2.141,0.977,0.84,0.306,0.236,0.165,0.462,0.668,0.09,0.099,0.043,NA,0.191,0.496,0.836,0.603,0.39
GPT-code-cushman-001,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,0.341,0.164,0.481,0.451,0.049,0.099,0.072,0.317,0,0,NA,NA,NA
GPT-code-davinci-002,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,0.54,0.684,0.686,0.805,0.568,0.41,0.433,0.463,0,0,NA,NA,NA
GPT-J,0.249,0.649,0.545,0.156,0.559,0.33,0.663,0.514,0.199,0.152,0.345,0.131,0.096,0.939,0.52,0.619,0.49,1.989,0.752,0.834,0.168,0.174,0.199,0.459,0.337,0.036,0.111,0.042,NA,0.175,0.479,0.673,0.194,0.307
GPT-NeoX,0.276,0.683,0.599,0.193,0.596,0.326,0.718,0.524,0.216,0.184,0.398,0.123,0.102,0.948,0.516,0.505,0.466,1.943,0.742,0.839,0.207,0.204,0.167,0.468,0.747,0.053,0.141,0.071,NA,0.191,0.515,0.705,0.82,0.316
InstructGPT-text-ada-001,0.238,0.464,0.238,0.025,0.149,0.176,0.429,0.346,0.232,0.134,0.302,0.136,0.034,0.822,0.503,0.406,1.61,3.505,1.975,0.728,0.119,0.063,0.145,0.226,0.161,0.004,0.02,0.001,NA,0.213,0.515,0.597,0.808,0.359
InstructGPT-text-babbage-001,0.229,0.451,0.429,0.07,0.33,0.284,0.561,0.452,0.233,0.208,0.449,0.151,0.046,0.913,0.499,0.509,1.103,2.946,1.326,0.77,0.15,0.123,0.212,0.289,0.231,0,0.016,0.007,NA,0.19,0.517,0.704,0.734,0.359
InstructGPT-text-curie-001,0.237,0.62,0.582,0.175,0.571,0.358,0.676,0.514,0.257,0.271,0.507,0.152,0.076,0.923,0.537,0.489,0.969,2.628,1.192,0.761,0.214,0.19,0.221,0.384,0.41,0.006,0.045,0.015,NA,0.172,0.442,0.791,0.852,0.342
InstructGPT-text-davinci-002,0.568,0.877,0.727,0.383,0.713,0.445,0.815,0.594,0.61,0.421,0.664,0.153,0.144,0.948,0.668,0.733,0.578,2.147,0.823,0.812,0.392,0.488,0.623,0.618,0.603,0.415,0.328,0.381,NA,0.229,0.615,0.842,0.931,0.881
InstructGPT-text-davinci-003,0.569,0.881,0.727,0.406,0.77,0.525,0.822,0.646,0.593,0.368,0.644,0.156,0.124,0.848,0.684,0.759,0.576,2.192,0.838,0.823,0.373,0.502,0.734,0.653,0.751,0.506,0.39,0.449,NA,0.233,0.622,0.839,0.93,0.862
J1-Grande-v1,0.27,0.722,0.672,0.233,0.578,0.362,0.739,0.52,0.193,0.161,0.341,0.143,0.122,0.953,0.529,0.658,0.6,2.205,0.868,0.803,0.269,0.247,0.154,0.458,0.696,0.054,0.08,0.045,NA,0.188,0.504,0.729,0.831,0.361
J1-Grande-v2-beta,0.445,0.812,0.725,0.337,0.625,0.392,0.764,0.56,0.306,0.285,0.46,0.146,0.152,0.957,0.546,0.679,0.602,2.156,0.836,0.805,0.313,0.286,0.139,0.47,0.617,0.096,0.127,0.068,NA,0.191,0.562,0.8,0.844,0.476
J1-Jumbo-v1,0.259,0.776,0.695,0.293,0.595,0.358,0.765,0.534,0.175,0.21,0.363,0.144,0.129,0.943,0.553,0.681,0.545,2.18,0.849,0.811,0.28,0.263,0.174,0.543,0.445,0.054,0.089,0.033,NA,0.232,0.484,0.735,0.841,0.378
J1-Large-v1,0.241,0.683,0.623,0.19,0.532,0.328,0.7,0.514,0.197,0.147,0.292,0.134,0.102,0.956,0.532,0.545,0.645,2.245,0.895,0.806,0.226,0.201,0.154,0.469,0.414,0.014,0.049,0.031,NA,0.196,0.514,0.729,0.827,0.352
Luminous-Base,0.27,0.719,0.605,0.202,0.568,0.334,NA,NA,0.182,NA,NA,0.11,0.105,0.939,0.544,0.473,NA,NA,NA,NA,0.275,0.209,0,0.452,0.517,0.026,0.089,0.026,NA,0.235,0.513,0.725,0.543,0.333
Luminous-Extended,0.321,0.767,0.665,0.254,0.609,0.349,NA,NA,0.221,NA,NA,0.139,0.124,0.947,0.524,0.523,NA,NA,NA,NA,0.308,0.225,0,0.475,0.666,0.067,0.111,0.035,NA,0.188,0.517,0.722,0.635,0.355
Luminous-Supreme,0.38,0.775,0.711,0.293,0.649,0.37,NA,NA,0.222,NA,NA,0.15,0.136,0.959,0.562,0.653,NA,NA,NA,NA,0.335,0.312,0,0.504,0.729,0.112,0.149,0.057,NA,0.212,0.53,0.758,0.707,0.411
OPT-175B,0.318,0.793,0.671,0.297,0.615,0.36,0.791,0.586,0.25,0.288,0.448,0.146,0.155,0.947,0.505,0.606,0.592,1.81,0.741,0.831,0.22,0.225,0.248,0.507,0.494,0.04,0.065,0.026,NA,0.22,0.532,0.722,0.374,0.347
OPT-6.7B,0.276,0.76,0.638,0.258,0.596,0.357,0.745,0.534,0.201,0.237,0.482,0.136,0.126,0.917,0.506,0.557,0.618,1.85,0.764,0.827,0.202,0.193,0.213,0.408,0.471,0.018,0.048,0.029,NA,0.175,0.527,0.718,0.466,0.355
T0pp,0.407,0,0.151,0.039,0.19,0.121,NA,NA,0.377,NA,NA,0.122,0.09,0.207,0.234,0.118,NA,NA,NA,NA,0.013,0,0.002,0,0.011,0,0,0,NA,0.186,0.611,0.004,0,0.491
T5,0.29,0.761,0.086,0.194,0.477,0.116,NA,NA,0.133,NA,NA,0.043,0.015,0.379,0.509,0.37,NA,NA,NA,NA,0.118,0.196,0.101,0.412,0.347,0.023,0,0,NA,0.159,0.558,0.624,0.652,0.312
TNLG-v2-530B,0.469,0.809,0.722,0.384,0.642,0.39,0.799,0.562,0.251,0.377,0.643,0.161,0.169,0.941,0.601,0.679,0.61,2.245,0.85,0.826,0.337,0.362,0.243,0.481,0.753,0.146,0.155,0.114,NA,0.228,0.58,0.811,0.881,0.479
TNLG-v2-6.7B,0.242,0.698,0.631,0.21,0.561,0.345,0.704,0.478,0.167,0.158,0.332,0.146,0.11,0.927,0.532,0.525,0.704,2.323,0.918,0.835,0.236,0.232,0.247,0.411,0.554,0.018,0.068,0.023,NA,0.19,0.504,0.826,0.694,0.337
UL2,0.291,0.746,0.083,0.204,0.349,0.144,NA,NA,0.193,NA,NA,0.03,0.058,0.337,0.521,0.404,NA,NA,NA,NA,0.168,0.205,0.187,0.501,0.14,0.024,0,0,NA,0.207,0.506,0.611,0.672,0.321
YaLM,0.243,0.634,0.252,0.068,0.227,0.162,NA,NA,0.202,NA,NA,0.017,0.021,0.836,0.49,0.395,NA,NA,NA,NA,0.049,0.056,0.061,0.346,0.633,0,0,0,NA,0.23,0.484,0.419,0.176,0.328